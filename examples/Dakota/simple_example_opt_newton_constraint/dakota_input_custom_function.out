Dakota version 6.2 released May 15 2015.
Subversion revision 3394 built Oct 13 2015 16:44:57.
Running serial Dakota executable in serial mode.
Start time: Thu Nov 12 08:16:47 2015

-------------------------------
Begin DAKOTA input file
dakota_input_custom_function.in
-------------------------------
## DAKOTA INPUT FILE - dakota_rosenbrock.in


environment,
	graphics
	tabular_graphics_data
	tabular_graphics_file = 'optim_res.dat'

method,
    #optpp_pds
    #coliny_cobyla
	#coliny_direct
	#hybrid collaborative optpp_q_newton
	#efficient_global
	#optpp_fd_newton
	#optpp_q_newton
	optpp_newton
     	max_iterations = 50           
     	convergence_tolerance = 1e-4 
	linear_inequality_constraint_matrix 1 0
	linear_inequality_upper_bounds nan
	linear_inequality_lower_bounds 1

variables,
	continuous_design = 2
	initial_point  4.2  -4.0
	
	#lower_bounds   -5.0 -5.0	
	#upper_bounds    5.0  5.0
	descriptors     'x1' 'x2'

interface,
	system
	analysis_driver = 'python myfunc.py'

responses,
	objective_functions = 1	
	descriptors = 'my_function'
	numerical_gradients
	#no_gradients
	#no_hessians
	numerical_hessians
---------------------
End DAKOTA input file
---------------------

Using Dakota input file 'dakota_input_custom_function.in'
Writing new restart file dakota.rst

>>>>> Executing environment.

>>>>> Running optpp_newton iterator.

------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> Initial map for analytic portion of response:

---------------------
Begin Evaluation    1
---------------------
Parameters for evaluation 1:
                      4.2000000000e+00 x1
                     -4.0000000000e+00 x2

python myfunc.py /tmp/dakota_params_bfc149df /tmp/dakota_results_8ed80240

Active response data for evaluation 1:
Active set vector = { 1 }
                      3.3640000000e+01 my_function


>>>>> Dakota finite difference gradient evaluation for x[1] + h:

---------------------
Begin Evaluation    2
---------------------
Parameters for evaluation 2:
                      4.2042000000e+00 x1
                     -4.0000000000e+00 x2

python myfunc.py /tmp/dakota_params_cf5ff745 /tmp/dakota_results_9c5b1201

Active response data for evaluation 2:
Active set vector = { 1 }
                      3.3675297640e+01 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] + 2h:

---------------------
Begin Evaluation    3
---------------------
Parameters for evaluation 3:
                      4.2168000000e+00 x1
                     -4.0000000000e+00 x2

python myfunc.py /tmp/dakota_params_7da50605 /tmp/dakota_results_e15cf8b5

Active response data for evaluation 3:
Active set vector = { 1 }
                      3.3781402240e+01 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] - 2h:

---------------------
Begin Evaluation    4
---------------------
Parameters for evaluation 4:
                      4.1832000000e+00 x1
                     -4.0000000000e+00 x2

python myfunc.py /tmp/dakota_params_ba4f9cbf /tmp/dakota_results_f3bfd2f0

Active response data for evaluation 4:
Active set vector = { 1 }
                      3.3499162240e+01 my_function


>>>>> Dakota finite difference gradient evaluation for x[2] + h:

---------------------
Begin Evaluation    5
---------------------
Parameters for evaluation 5:
                      4.2000000000e+00 x1
                     -4.0040000000e+00 x2

python myfunc.py /tmp/dakota_params_7dd7ea3d /tmp/dakota_results_de066935

Active response data for evaluation 5:
Active set vector = { 1 }
                      3.3672016000e+01 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + 2h:

---------------------
Begin Evaluation    6
---------------------
Parameters for evaluation 6:
                      4.2000000000e+00 x1
                     -4.0160000000e+00 x2

python myfunc.py /tmp/dakota_params_f20bb349 /tmp/dakota_results_d79a3b12

Active response data for evaluation 6:
Active set vector = { 1 }
                      3.3768256000e+01 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] - 2h:

---------------------
Begin Evaluation    7
---------------------
Parameters for evaluation 7:
                      4.2000000000e+00 x1
                     -3.9840000000e+00 x2

python myfunc.py /tmp/dakota_params_5428f192 /tmp/dakota_results_e6e74374

Active response data for evaluation 7:
Active set vector = { 1 }
                      3.3512256000e+01 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + h, x[1] + h:

---------------------
Begin Evaluation    8
---------------------
Parameters for evaluation 8:
                      4.2168000000e+00 x1
                     -4.0160000000e+00 x2

python myfunc.py /tmp/dakota_params_fd737321 /tmp/dakota_results_fe81ad51

Active response data for evaluation 8:
Active set vector = { 1 }
                      3.3909658240e+01 my_function


>>>>> Total response returned to iterator:

Active set vector = { 7 } Deriv vars vector = { 1 2 }
                      3.3640000000e+01 my_function
 [  8.4042000000e+00 -8.0040000000e+00 ] my_function gradient
[[  2.0000000000e+00 -0.0000000000e+00 
   -0.0000000000e+00  2.0000000000e+00 ]] my_function Hessian



---------------------
Begin Evaluation    9
---------------------
Parameters for evaluation 9:
                      3.1189190150e+00 x1
                      1.9999999958e-03 x2

python myfunc.py /tmp/dakota_params_fa793f0d /tmp/dakota_results_7e3a0eb3

Active response data for evaluation 9:
Active set vector = { 1 }
                      9.7276598220e+00 my_function



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference gradient evaluation for x[1] + h:

---------------------
Begin Evaluation   10
---------------------
Parameters for evaluation 10:
                      3.1220379340e+00 x1
                      1.9999999958e-03 x2

python myfunc.py /tmp/dakota_params_8b331042 /tmp/dakota_results_961b8a11

Active response data for evaluation 10:
Active set vector = { 1 }
                      9.7471248613e+00 my_function


>>>>> Dakota finite difference gradient evaluation for x[2] + h:

---------------------
Begin Evaluation   11
---------------------
Parameters for evaluation 11:
                      3.1189190150e+00 x1
                      2.0099999958e-03 x2

python myfunc.py /tmp/dakota_params_7758193f /tmp/dakota_results_af62abb5

Active response data for evaluation 11:
Active set vector = { 1 }
                      9.7276598621e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 2 } Deriv vars vector = { 1 2 }
 [  6.2409569458e+00  4.0099999765e-03 ] my_function gradient



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference Hessian evaluation for x[1] + 2h:

---------------------
Begin Evaluation   12
---------------------
Parameters for evaluation 12:
                      3.1313946910e+00 x1
                      1.9999999958e-03 x2

python myfunc.py /tmp/dakota_params_15e95b0d /tmp/dakota_results_b9725298

Active response data for evaluation 12:
Active set vector = { 1 }
                      9.8056367111e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] - 2h:

---------------------
Begin Evaluation   13
---------------------
Parameters for evaluation 13:
                      3.1064433389e+00 x1
                      1.9999999958e-03 x2

python myfunc.py /tmp/dakota_params_6cefafaf /tmp/dakota_results_b68de2c0

Active response data for evaluation 13:
Active set vector = { 1 }
                      9.6499942179e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + 2h:

---------------------
Begin Evaluation   14
---------------------
Parameters for evaluation 14:
                      3.1189190150e+00 x1
                      2.0399999958e-03 x2

python myfunc.py /tmp/dakota_params_f0e65999 /tmp/dakota_results_afa91a6b

Active response data for evaluation 14:
Active set vector = { 1 }
                      9.7276599836e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] - 2h:

---------------------
Begin Evaluation   15
---------------------
Parameters for evaluation 15:
                      3.1189190150e+00 x1
                      1.9599999958e-03 x2

python myfunc.py /tmp/dakota_params_26c401f3 /tmp/dakota_results_45f275f2

Active response data for evaluation 15:
Active set vector = { 1 }
                      9.7276596636e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + h, x[1] + h:

---------------------
Begin Evaluation   16
---------------------
Parameters for evaluation 16:
                      3.1313946910e+00 x1
                      2.0399999958e-03 x2

python myfunc.py /tmp/dakota_params_18c0f931 /tmp/dakota_results_d9aa7af7

Active response data for evaluation 16:
Active set vector = { 1 }
                      9.8056368727e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 4 } Deriv vars vector = { 1 2 }
[[  1.9999998952e+00  3.5596404373e-09 
    3.5596404373e-09  1.9999990553e+00 ]] my_function Hessian



---------------------
Begin Evaluation   17
---------------------
Parameters for evaluation 17:
                      1.8641517422e+00 x1
                     -4.9987062652e-06 x2

python myfunc.py /tmp/dakota_params_7d60656f /tmp/dakota_results_dcc78a5d

Active response data for evaluation 17:
Active set vector = { 1 }
                      3.4750617180e+00 my_function



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference gradient evaluation for x[1] + h:

---------------------
Begin Evaluation   18
---------------------
Parameters for evaluation 18:
                      1.8660158940e+00 x1
                     -4.9987062652e-06 x2

python myfunc.py /tmp/dakota_params_8c9308a7 /tmp/dakota_results_cfd2f728

Active response data for evaluation 18:
Active set vector = { 1 }
                      3.4820153165e+00 my_function


>>>>> Dakota finite difference gradient evaluation for x[2] + h:

---------------------
Begin Evaluation   19
---------------------
Parameters for evaluation 19:
                      1.8641517422e+00 x1
                     -1.4998706265e-05 x2

python myfunc.py /tmp/dakota_params_ca2240b6 /tmp/dakota_results_4ee45556

Active response data for evaluation 19:
Active set vector = { 1 }
                      3.4750617182e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 2 } Deriv vars vector = { 1 2 }
 [  3.7301676320e+00 -2.0000001655e-05 ] my_function gradient



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference Hessian evaluation for x[1] + 2h:

---------------------
Begin Evaluation   20
---------------------
Parameters for evaluation 20:
                      1.8716083492e+00 x1
                     -4.9987062652e-06 x2

python myfunc.py /tmp/dakota_params_6762f9aa /tmp/dakota_results_4c1ae74f

Active response data for evaluation 20:
Active set vector = { 1 }
                      3.5029178127e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] - 2h:

---------------------
Begin Evaluation   21
---------------------
Parameters for evaluation 21:
                      1.8566951352e+00 x1
                     -4.9987062652e-06 x2

python myfunc.py /tmp/dakota_params_b97f7699 /tmp/dakota_results_8d56ecf3

Active response data for evaluation 21:
Active set vector = { 1 }
                      3.4473168253e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + 2h:

---------------------
Begin Evaluation   22
---------------------
Parameters for evaluation 22:
                      1.8641517422e+00 x1
                     -4.4998706265e-05 x2

python myfunc.py /tmp/dakota_params_ee0c2e78 /tmp/dakota_results_f861617a

Active response data for evaluation 22:
Active set vector = { 1 }
                      3.4750617200e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] - 2h:

---------------------
Begin Evaluation   23
---------------------
Parameters for evaluation 23:
                      1.8641517422e+00 x1
                      3.5001293735e-05 x2

python myfunc.py /tmp/dakota_params_82d91141 /tmp/dakota_results_c8da4b8d

Active response data for evaluation 23:
Active set vector = { 1 }
                      3.4750617192e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + h, x[1] + h:

---------------------
Begin Evaluation   24
---------------------
Parameters for evaluation 24:
                      1.8716083492e+00 x1
                     -4.4998706265e-05 x2

python myfunc.py /tmp/dakota_params_57e3521d /tmp/dakota_results_7e256811

Active response data for evaluation 24:
Active set vector = { 1 }
                      3.5029178147e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 4 } Deriv vars vector = { 1 2 }
[[  1.9999999105e+00 -1.4889118191e-09 
   -1.4889118191e-09  1.9999998879e+00 ]] my_function Hessian



---------------------
Begin Evaluation   25
---------------------
Parameters for evaluation 25:
                      1.2873547064e+00 x1
                      5.0008657226e-06 x2

python myfunc.py /tmp/dakota_params_e3dc2035 /tmp/dakota_results_b2051c66

Active response data for evaluation 25:
Active set vector = { 1 }
                      1.6572821401e+00 my_function



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference gradient evaluation for x[1] + h:

---------------------
Begin Evaluation   26
---------------------
Parameters for evaluation 26:
                      1.2886420611e+00 x1
                      5.0008657226e-06 x2

python myfunc.py /tmp/dakota_params_5646ec9d /tmp/dakota_results_668b1c36

Active response data for evaluation 26:
Active set vector = { 1 }
                      1.6605983616e+00 my_function


>>>>> Dakota finite difference gradient evaluation for x[2] + h:

---------------------
Begin Evaluation   27
---------------------
Parameters for evaluation 27:
                      1.2873547064e+00 x1
                      1.5000865723e-05 x2

python myfunc.py /tmp/dakota_params_288f7790 /tmp/dakota_results_bd0ff606

Active response data for evaluation 27:
Active set vector = { 1 }
                      1.6572821403e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 2 } Deriv vars vector = { 1 2 }
 [  2.5759967657e+00  2.0000001655e-05 ] my_function gradient



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference Hessian evaluation for x[1] + 2h:

---------------------
Begin Evaluation   28
---------------------
Parameters for evaluation 28:
                      1.2925041252e+00 x1
                      5.0008657226e-06 x2

python myfunc.py /tmp/dakota_params_c081db11 /tmp/dakota_results_dca0f951

Active response data for evaluation 28:
Active set vector = { 1 }
                      1.6705669137e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] - 2h:

---------------------
Begin Evaluation   29
---------------------
Parameters for evaluation 29:
                      1.2822052876e+00 x1
                      5.0008657226e-06 x2

python myfunc.py /tmp/dakota_params_31237f38 /tmp/dakota_results_d6ebf3c2

Active response data for evaluation 29:
Active set vector = { 1 }
                      1.6440503994e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + 2h:

---------------------
Begin Evaluation   30
---------------------
Parameters for evaluation 30:
                      1.2873547064e+00 x1
                      4.5000865723e-05 x2

python myfunc.py /tmp/dakota_params_ec2abd63 /tmp/dakota_results_cfead23d

Active response data for evaluation 30:
Active set vector = { 1 }
                      1.6572821421e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] - 2h:

---------------------
Begin Evaluation   31
---------------------
Parameters for evaluation 31:
                      1.2873547064e+00 x1
                     -3.4999134277e-05 x2

python myfunc.py /tmp/dakota_params_da7e0b8d /tmp/dakota_results_a0d12ae5

Active response data for evaluation 31:
Active set vector = { 1 }
                      1.6572821413e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + h, x[1] + h:

---------------------
Begin Evaluation   32
---------------------
Parameters for evaluation 32:
                      1.2925041252e+00 x1
                      4.5000865723e-05 x2

python myfunc.py /tmp/dakota_params_33ac1a59 /tmp/dakota_results_e57482c2

Active response data for evaluation 32:
Active set vector = { 1 }
                      1.6705669157e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 4 } Deriv vars vector = { 1 2 }
[[  1.9999996802e+00  0.0000000000e+00 
    0.0000000000e+00  2.0000000267e+00 ]] my_function Hessian



---------------------
Begin Evaluation   33
---------------------
Parameters for evaluation 33:
                      1.0760288152e+00 x1
                     -4.9991349713e-06 x2

python myfunc.py /tmp/dakota_params_31e91084 /tmp/dakota_results_e141baa0

Active response data for evaluation 33:
Active set vector = { 1 }
                      1.1578380111e+00 my_function



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference gradient evaluation for x[1] + h:

---------------------
Begin Evaluation   34
---------------------
Parameters for evaluation 34:
                      1.0771048440e+00 x1
                     -4.9991349713e-06 x2

python myfunc.py /tmp/dakota_params_8d5914d2 /tmp/dakota_results_557039a3

Active response data for evaluation 34:
Active set vector = { 1 }
                      1.1601548450e+00 my_function


>>>>> Dakota finite difference gradient evaluation for x[2] + h:

---------------------
Begin Evaluation   35
---------------------
Parameters for evaluation 35:
                      1.0760288152e+00 x1
                     -1.4999134971e-05 x2

python myfunc.py /tmp/dakota_params_fdaa41d0 /tmp/dakota_results_caf7dca2

Active response data for evaluation 35:
Active set vector = { 1 }
                      1.1578380113e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 2 } Deriv vars vector = { 1 2 }
 [  2.1531336590e+00 -2.0000001655e-05 ] my_function gradient



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference Hessian evaluation for x[1] + 2h:

---------------------
Begin Evaluation   36
---------------------
Parameters for evaluation 36:
                      1.0803329304e+00 x1
                     -4.9991349713e-06 x2

python myfunc.py /tmp/dakota_params_2e41cb35 /tmp/dakota_results_b5015d64

Active response data for evaluation 36:
Active set vector = { 1 }
                      1.1671192406e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] - 2h:

---------------------
Begin Evaluation   37
---------------------
Parameters for evaluation 37:
                      1.0717246999e+00 x1
                     -4.9991349713e-06 x2

python myfunc.py /tmp/dakota_params_901546b3 /tmp/dakota_results_1187c7ff

Active response data for evaluation 37:
Active set vector = { 1 }
                      1.1485938324e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + 2h:

---------------------
Begin Evaluation   38
---------------------
Parameters for evaluation 38:
                      1.0760288152e+00 x1
                     -4.4999134971e-05 x2

python myfunc.py /tmp/dakota_params_e23f0f8b /tmp/dakota_results_061086c6

Active response data for evaluation 38:
Active set vector = { 1 }
                      1.1578380131e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] - 2h:

---------------------
Begin Evaluation   39
---------------------
Parameters for evaluation 39:
                      1.0760288152e+00 x1
                      3.5000865029e-05 x2

python myfunc.py /tmp/dakota_params_48eab810 /tmp/dakota_results_b359530d

Active response data for evaluation 39:
Active set vector = { 1 }
                      1.1578380123e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + h, x[1] + h:

---------------------
Begin Evaluation   40
---------------------
Parameters for evaluation 40:
                      1.0803329304e+00 x1
                     -4.4999134971e-05 x2

python myfunc.py /tmp/dakota_params_7584dd81 /tmp/dakota_results_e29f823b

Active response data for evaluation 40:
Active set vector = { 1 }
                      1.1671192426e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 4 } Deriv vars vector = { 1 2 }
[[  1.9999996570e+00 -1.2897226926e-09 
   -1.2897226926e-09  2.0000000267e+00 ]] my_function Hessian



---------------------
Begin Evaluation   41
---------------------
Parameters for evaluation 41:
                      1.0372403281e+00 x1
                      5.0008407094e-06 x2

python myfunc.py /tmp/dakota_params_17bc5d2f /tmp/dakota_results_ae2c15ed

Active response data for evaluation 41:
Active set vector = { 1 }
                      1.0758674983e+00 my_function



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference gradient evaluation for x[1] + h:

---------------------
Begin Evaluation   42
---------------------
Parameters for evaluation 42:
                      1.0382775685e+00 x1
                      5.0008407094e-06 x2

python myfunc.py /tmp/dakota_params_20715385 /tmp/dakota_results_498537d3

Active response data for evaluation 42:
Active set vector = { 1 }
                      1.0780203092e+00 my_function


>>>>> Dakota finite difference gradient evaluation for x[2] + h:

---------------------
Begin Evaluation   43
---------------------
Parameters for evaluation 43:
                      1.0372403281e+00 x1
                      1.5000840709e-05 x2

python myfunc.py /tmp/dakota_params_71e527a3 /tmp/dakota_results_56830c93

Active response data for evaluation 43:
Active set vector = { 1 }
                      1.0758674985e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 2 } Deriv vars vector = { 1 2 }
 [  2.0755178926e+00  2.0000001655e-05 ] my_function gradient



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference Hessian evaluation for x[1] + 2h:

---------------------
Begin Evaluation   44
---------------------
Parameters for evaluation 44:
                      1.0413892894e+00 x1
                      5.0008407094e-06 x2

python myfunc.py /tmp/dakota_params_efd09457 /tmp/dakota_results_d801602e

Active response data for evaluation 44:
Active set vector = { 1 }
                      1.0844916522e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] - 2h:

---------------------
Begin Evaluation   45
---------------------
Parameters for evaluation 45:
                      1.0330913668e+00 x1
                      5.0008407094e-06 x2

python myfunc.py /tmp/dakota_params_e5c3ecff /tmp/dakota_results_99b3b421

Active response data for evaluation 45:
Active set vector = { 1 }
                      1.0672777722e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + 2h:

---------------------
Begin Evaluation   46
---------------------
Parameters for evaluation 46:
                      1.0372403281e+00 x1
                      4.5000840709e-05 x2

python myfunc.py /tmp/dakota_params_89a4d94d /tmp/dakota_results_bd7d1544

Active response data for evaluation 46:
Active set vector = { 1 }
                      1.0758675003e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] - 2h:

---------------------
Begin Evaluation   47
---------------------
Parameters for evaluation 47:
                      1.0372403281e+00 x1
                     -3.4999159291e-05 x2

python myfunc.py /tmp/dakota_params_c5227f9e /tmp/dakota_results_f34de5bd

Active response data for evaluation 47:
Active set vector = { 1 }
                      1.0758674995e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + h, x[1] + h:

---------------------
Begin Evaluation   48
---------------------
Parameters for evaluation 48:
                      1.0413892894e+00 x1
                      4.5000840709e-05 x2

python myfunc.py /tmp/dakota_params_0b027380 /tmp/dakota_results_c9142a82

Active response data for evaluation 48:
Active set vector = { 1 }
                      1.0844916542e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 4 } Deriv vars vector = { 1 2 }
[[  1.9999994222e+00  0.0000000000e+00 
    0.0000000000e+00  1.9999998879e+00 ]] my_function Hessian



---------------------
Begin Evaluation   49
---------------------
Parameters for evaluation 49:
                      1.0016362040e+00 x1
                     -4.9991606784e-06 x2

python myfunc.py /tmp/dakota_params_e83c235e /tmp/dakota_results_1ceeb20a

Active response data for evaluation 49:
Active set vector = { 1 }
                      1.0032750851e+00 my_function



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference gradient evaluation for x[1] + h:

---------------------
Begin Evaluation   50
---------------------
Parameters for evaluation 50:
                      1.0026378402e+00 x1
                     -4.9991606784e-06 x2

python myfunc.py /tmp/dakota_params_faeeef31 /tmp/dakota_results_a86fc473

Active response data for evaluation 50:
Active set vector = { 1 }
                      1.0052826386e+00 my_function


>>>>> Dakota finite difference gradient evaluation for x[2] + h:

---------------------
Begin Evaluation   51
---------------------
Parameters for evaluation 51:
                      1.0016362040e+00 x1
                     -1.4999160678e-05 x2

python myfunc.py /tmp/dakota_params_9b9672da /tmp/dakota_results_58881117

Active response data for evaluation 51:
Active set vector = { 1 }
                      1.0032750853e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 2 } Deriv vars vector = { 1 2 }
 [  2.0042740489e+00 -2.0000001655e-05 ] my_function gradient



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference Hessian evaluation for x[1] + 2h:

---------------------
Begin Evaluation   52
---------------------
Parameters for evaluation 52:
                      1.0056427488e+00 x1
                     -4.9991606784e-06 x2

python myfunc.py /tmp/dakota_params_12c63a62 /tmp/dakota_results_31ec31ab

Active response data for evaluation 52:
Active set vector = { 1 }
                      1.0113173382e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] - 2h:

---------------------
Begin Evaluation   53
---------------------
Parameters for evaluation 53:
                      9.9762965915e-01 x1
                     -4.9991606784e-06 x2

python myfunc.py /tmp/dakota_params_63eeef8f /tmp/dakota_results_009f1b2b

Active response data for evaluation 53:
Active set vector = { 1 }
                      9.9526493684e-01 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + 2h:

---------------------
Begin Evaluation   54
---------------------
Parameters for evaluation 54:
                      1.0016362040e+00 x1
                     -4.4999160678e-05 x2

python myfunc.py /tmp/dakota_params_9402bbd3 /tmp/dakota_results_7721fb25

Active response data for evaluation 54:
Active set vector = { 1 }
                      1.0032750871e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] - 2h:

---------------------
Begin Evaluation   55
---------------------
Parameters for evaluation 55:
                      1.0016362040e+00 x1
                      3.5000839322e-05 x2

python myfunc.py /tmp/dakota_params_bdd2da23 /tmp/dakota_results_64469024

Active response data for evaluation 55:
Active set vector = { 1 }
                      1.0032750863e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + h, x[1] + h:

---------------------
Begin Evaluation   56
---------------------
Parameters for evaluation 56:
                      1.0056427488e+00 x1
                     -4.4999160678e-05 x2

python myfunc.py /tmp/dakota_params_60d2b09b /tmp/dakota_results_af5dd0df

Active response data for evaluation 56:
Active set vector = { 1 }
                      1.0113173402e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 4 } Deriv vars vector = { 1 2 }
[[  1.9999999549e+00 -0.0000000000e+00 
   -0.0000000000e+00  1.9999998879e+00 ]] my_function Hessian



---------------------
Begin Evaluation   57
---------------------
Parameters for evaluation 57:
                      1.0003726791e+00 x1
                      5.0008407094e-06 x2

python myfunc.py /tmp/dakota_params_4b8bae38 /tmp/dakota_results_7b65bf12

Active response data for evaluation 57:
Active set vector = { 1 }
                      1.0007454970e+00 my_function



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference gradient evaluation for x[1] + h:

---------------------
Begin Evaluation   58
---------------------
Parameters for evaluation 58:
                      1.0013730517e+00 x1
                      5.0008407094e-06 x2

python myfunc.py /tmp/dakota_params_4feb6813 /tmp/dakota_results_3184fd81

Active response data for evaluation 58:
Active set vector = { 1 }
                      1.0027479888e+00 my_function


>>>>> Dakota finite difference gradient evaluation for x[2] + h:

---------------------
Begin Evaluation   59
---------------------
Parameters for evaluation 59:
                      1.0003726791e+00 x1
                      1.5000840709e-05 x2

python myfunc.py /tmp/dakota_params_83fecd2c /tmp/dakota_results_b67f0bc2

Active response data for evaluation 59:
Active set vector = { 1 }
                      1.0007454972e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 2 } Deriv vars vector = { 1 2 }
 [  2.0017457313e+00  2.0000001655e-05 ] my_function gradient



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference Hessian evaluation for x[1] + 2h:

---------------------
Begin Evaluation   60
---------------------
Parameters for evaluation 60:
                      1.0043741698e+00 x1
                      5.0008407094e-06 x2

python myfunc.py /tmp/dakota_params_595bc1d2 /tmp/dakota_results_a57713fa

Active response data for evaluation 60:
Active set vector = { 1 }
                      1.0087674729e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] - 2h:

---------------------
Begin Evaluation   61
---------------------
Parameters for evaluation 61:
                      9.9637118834e-01 x1
                      5.0008407094e-06 x2

python myfunc.py /tmp/dakota_params_1713af1f /tmp/dakota_results_22a2261e

Active response data for evaluation 61:
Active set vector = { 1 }
                      9.9275554499e-01 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + 2h:

---------------------
Begin Evaluation   62
---------------------
Parameters for evaluation 62:
                      1.0003726791e+00 x1
                      4.5000840709e-05 x2

python myfunc.py /tmp/dakota_params_10fada94 /tmp/dakota_results_d41a2182

Active response data for evaluation 62:
Active set vector = { 1 }
                      1.0007454990e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] - 2h:

---------------------
Begin Evaluation   63
---------------------
Parameters for evaluation 63:
                      1.0003726791e+00 x1
                     -3.4999159291e-05 x2

python myfunc.py /tmp/dakota_params_a15ff688 /tmp/dakota_results_c7f1ff89

Active response data for evaluation 63:
Active set vector = { 1 }
                      1.0007454982e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + h, x[1] + h:

---------------------
Begin Evaluation   64
---------------------
Parameters for evaluation 64:
                      1.0043741698e+00 x1
                      4.5000840709e-05 x2

python myfunc.py /tmp/dakota_params_66d57b1d /tmp/dakota_results_1f4f2a4a

Active response data for evaluation 64:
Active set vector = { 1 }
                      1.0087674749e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 4 } Deriv vars vector = { 1 2 }
[[  1.9999995688e+00  0.0000000000e+00 
    0.0000000000e+00  1.9999998879e+00 ]] my_function Hessian



---------------------
Begin Evaluation   65
---------------------
Parameters for evaluation 65:
                      1.0000038482e+00 x1
                     -4.9991606784e-06 x2

python myfunc.py /tmp/dakota_params_5bc7815d /tmp/dakota_results_1d3f283e

Active response data for evaluation 65:
Active set vector = { 1 }
                      1.0000076964e+00 my_function



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference gradient evaluation for x[1] + h:

---------------------
Begin Evaluation   66
---------------------
Parameters for evaluation 66:
                      1.0010038520e+00 x1
                     -4.9991606784e-06 x2

python myfunc.py /tmp/dakota_params_a5a838ea /tmp/dakota_results_d5a1de2b

Active response data for evaluation 66:
Active set vector = { 1 }
                      1.0020087118e+00 my_function


>>>>> Dakota finite difference gradient evaluation for x[2] + h:

---------------------
Begin Evaluation   67
---------------------
Parameters for evaluation 67:
                      1.0000038482e+00 x1
                     -1.4999160678e-05 x2

python myfunc.py /tmp/dakota_params_7d43217a /tmp/dakota_results_52e17361

Active response data for evaluation 67:
Active set vector = { 1 }
                      1.0000076966e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 2 } Deriv vars vector = { 1 2 }
 [  2.0010076997e+00 -2.0000001655e-05 ] my_function gradient



------------------------------------------
Begin Dakota derivative estimation routine
------------------------------------------

>>>>> map at X performed previously and results retrieved

>>>>> Dakota finite difference Hessian evaluation for x[1] + 2h:

---------------------
Begin Evaluation   68
---------------------
Parameters for evaluation 68:
                      1.0040038636e+00 x1
                     -4.9991606784e-06 x2

python myfunc.py /tmp/dakota_params_aa1a98f2 /tmp/dakota_results_49183148

Active response data for evaluation 68:
Active set vector = { 1 }
                      1.0080237581e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[1] - 2h:

---------------------
Begin Evaluation   69
---------------------
Parameters for evaluation 69:
                      9.9600383279e-01 x1
                     -4.9991606784e-06 x2

python myfunc.py /tmp/dakota_params_044f9d60 /tmp/dakota_results_0996b008

Active response data for evaluation 69:
Active set vector = { 1 }
                      9.9202363497e-01 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + 2h:

---------------------
Begin Evaluation   70
---------------------
Parameters for evaluation 70:
                      1.0000038482e+00 x1
                     -4.4999160678e-05 x2

python myfunc.py /tmp/dakota_params_1ad7b5b2 /tmp/dakota_results_05e1e16a

Active response data for evaluation 70:
Active set vector = { 1 }
                      1.0000076984e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] - 2h:

---------------------
Begin Evaluation   71
---------------------
Parameters for evaluation 71:
                      1.0000038482e+00 x1
                      3.5000839322e-05 x2

python myfunc.py /tmp/dakota_params_934512ed /tmp/dakota_results_495387ea

Active response data for evaluation 71:
Active set vector = { 1 }
                      1.0000076976e+00 my_function


>>>>> Dakota finite difference Hessian evaluation for x[2] + h, x[1] + h:

---------------------
Begin Evaluation   72
---------------------
Parameters for evaluation 72:
                      1.0040038636e+00 x1
                     -4.4999160678e-05 x2

python myfunc.py /tmp/dakota_params_76961e66 /tmp/dakota_results_d57ce77a

Active response data for evaluation 72:
Active set vector = { 1 }
                      1.0080237601e+00 my_function


>>>>> Total response returned to iterator:

Active set vector = { 4 } Deriv vars vector = { 1 2 }
[[  2.0000005447e+00 -0.0000000000e+00 
   -0.0000000000e+00  2.0000000267e+00 ]] my_function Hessian


********************************************************
             OPT++ TERMINATION CRITERION                
	  SUCCESS - optpp_newton converged to a solution
Algorithm converged - Norm of gradient less than relative gradient tolerance
********************************************************
<<<<< Function evaluation summary: 72 total (72 new, 0 duplicate)
<<<<< Best parameters          =
                      1.0000038482e+00 x1
                     -4.9991606784e-06 x2
<<<<< Best objective function  =
                      1.0000076964e+00
<<<<< Best data captured at function evaluation 65


<<<<< Iterator optpp_newton completed.
<<<<< Environment execution completed.
DAKOTA execution time in seconds:
  Total CPU        =    0.10464 [parent =      0.104, child =    0.00064]
  Total wall clock =    8.72478
